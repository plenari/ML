{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nPyTorch: \u53d8\u91cf\u548cautograd\n-------------------------------\n\n\u672c\u4f8b\u4e2d\u7684\u5168\u8fde\u63a5\u795e\u7ecf\u7f51\u7edc\u6709\u4e00\u4e2a\u9690\u85cf\u5c42, \u540e\u63a5ReLU\u6fc0\u6d3b\u5c42, \u5e76\u4e14\u4e0d\u5e26\u504f\u7f6e\u53c2\u6570. \n\u8bad\u7ec3\u65f6\u901a\u8fc7\u6700\u5c0f\u5316\u6b27\u5f0f\u8ddd\u79bb\u7684\u5e73\u65b9, \u6765\u5b66\u4e60\u4ecex\u5230y\u7684\u6620\u5c04.\n\n\u5728\u5b9e\u73b0\u4e2d, \u6211\u4eec\u5c06\u4f7f\u7528PyTorch\u53d8\u91cf\u7684\u51fd\u6570\u6765\u8fdb\u884c\u524d\u5411\u8ba1\u7b97, \u5e76\u7528PyTorch\u7684autograd\u8ba1\u7b97\u68af\u5ea6\n\nPyTorch\u53d8\u91cf\u662fPyTorch\u5f20\u91cf\u7684\u5c01\u88c5, \u8868\u793a\u8ba1\u7b97\u56fe\u4e2d\u7684\u4e00\u4e2a\u8282\u70b9. \u5982\u679cx\u662f\u53d8\u91cf, \u90a3\u4e48x.data\u5c31\u662f\n\u8868\u793a\u5176\u503c\u7684\u5f20\u91cf, \u800cx.grad\u5219\u662f\u53e6\u4e00\u4e2a\u53d8\u91cf, \u5176\u4e2d\u5305\u542b\u67d0\u4e2a\u6807\u91cf\u5173\u4e8ex\u7684\u68af\u5ea6.\n\nPyTorch\u53d8\u91cf\u7684API\u548c\u5f20\u91cf\u662f\u4e00\u6837\u7684: \u51e0\u4e4e\u6240\u6709Tensor\u4e0a\u80fd\u505a\u7684\u64cd\u4f5c, \u4f60\u5728\u53d8\u91cf\u4e0a\u4e5f\u53ef\u4ee5\u8c03\u7528. \u533a\u522b\n\u5728\u4e8e\u7528\u53d8\u91cf\u65f6, autograd\u53ef\u4ee5\u81ea\u52a8\u8ba1\u7b97\u68af\u5ea6.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom torch.autograd import Variable\n\ndtype = torch.FloatTensor\n# dtype = torch.cuda.FloatTensor # \u53d6\u6d88\u6ce8\u91ca\u4ee5\u5728GPU\u4e0a\u8fd0\u884c\n\n# N \u6279\u91cf\u5927\u5c0f; D_in\u662f\u8f93\u5165\u5c3a\u5bf8;\n# H\u662f\u9690\u85cf\u5c3a\u5bf8; D_out\u662f\u8f93\u51fa\u5c3a\u5bf8.\nN, D_in, H, D_out = 64, 1000, 100, 10\n\n# \u521b\u5efa\u968f\u673a\u5f20\u91cf\u6765\u4fdd\u5b58\u8f93\u5165\u548c\u8f93\u51fa,\u5e76\u5c06\u5b83\u4eec\u5305\u88c5\u5728\u53d8\u91cf\u4e2d.\n# \u8bbe\u7f6erequires_grad = False, \u56e0\u4e3a\u5728\u540e\u5411\u4f20\u64ad\u65f6, \u6211\u4eec\u5e76\u4e0d\u9700\u8981\u8ba1\u7b97\u5173\u4e8e\u8fd9\u4e9b\u53d8\u91cf\u7684\u68af\u5ea6\nx = Variable(torch.randn(N, D_in).type(dtype), requires_grad=False)\ny = Variable(torch.randn(N, D_out).type(dtype), requires_grad=False)\n\n# \u4e3a\u6743\u91cd\u521b\u5efa\u968f\u673a\u5f20\u91cf,\u5e76\u5c06\u5176\u5305\u88c5\u5728\u53d8\u91cf\u4e2d.\n# \u8bbe\u7f6erequires_grad = True, \u56e0\u4e3a\u5728\u540e\u5411\u4f20\u64ad\u65f6, \u6211\u4eec\u9700\u8981\u8ba1\u7b97\u5173\u4e8e\u8fd9\u4e9b\u53d8\u91cf\u7684\u68af\u5ea6\nw1 = Variable(torch.randn(D_in, H).type(dtype), requires_grad=True)\nw2 = Variable(torch.randn(H, D_out).type(dtype), requires_grad=True)\n\nlearning_rate = 1e-6\nfor t in range(500):\n    # \u6b63\u5411\u4f20\u9012:\u4f7f\u7528\u53d8\u91cf\u4e0a\u7684\u8fd0\u7b97\u6765\u8ba1\u7b97\u9884\u6d4b\u7684y; \u8fd9\u4e9b\n    # \u4e0e\u6211\u4eec\u7528\u4e8e\u8ba1\u7b97\u4f7f\u7528\u5f20\u91cf\u7684\u6b63\u5411\u4f20\u9012\u5b8c\u5168\u76f8\u540c,\n    # \u4f46\u6211\u4eec\u4e0d\u9700\u8981\u4fdd\u7559\u5bf9\u4e2d\u95f4\u503c\u7684\u5f15\u7528,\n    # \u56e0\u4e3a\u6211\u4eec\u6ca1\u6709\u5b9e\u73b0\u5411\u540e\u4f20\u9012.\n    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n\n    # \u4f7f\u7528\u53d8\u91cf\u4e0a\u7684\u64cd\u4f5c\u8ba1\u7b97\u548c\u6253\u5370\u635f\u5931.\n    # \u73b0\u5728\u635f\u5931\u662f\u5f62\u72b6\u53d8\u91cf (1,) \u5e76\u4e14 loss.data \u662f\u5f62\u72b6\u7684\u5f20\u91cf\n    # (1,); loss.data[0] \u662f\u6301\u6709\u635f\u5931\u7684\u6807\u91cf\u503c.\n    loss = (y_pred - y).pow(2).sum()\n    print(t, loss.data[0])\n\n    # \u4f7f\u7528autograd\u6765\u8ba1\u7b97\u53cd\u5411\u4f20\u9012. \n    # \u8be5\u8c03\u7528\u5c06\u4f7f\u7528requires_grad = True\u6765\u8ba1\u7b97\u76f8\u5bf9\u4e8e\u6240\u6709\u53d8\u91cf\u7684\u635f\u5931\u68af\u5ea6.\n    # \u5728\u8fd9\u6b21\u8c03\u7528\u4e4b\u540e w1.grad \u548c w2.grad \u5c06\u662f\u53d8\u91cf\n    # \u5b83\u4eec\u5206\u522b\u76f8\u5bf9\u4e8ew1\u548cw2\u4fdd\u5b58\u635f\u5931\u7684\u68af\u5ea6.\n    loss.backward()\n\n    # \u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u66f4\u65b0\u6743\u91cd; w1.data \u548c w2.data \u662f\u5f20\u91cf,\n    # w1.grad \u548c w2.grad \u662f\u53d8\u91cf\u5e76\u4e14 w1.grad.data \u548c w2.grad.data \n    # \u662f\u5f20\u91cf.\n    w1.data -= learning_rate * w1.grad.data\n    w2.data -= learning_rate * w2.grad.data\n\n    # \u66f4\u65b0\u6743\u91cd\u540e\u624b\u52a8\u5c06\u68af\u5ea6\u5f52\u96f6\n    w1.grad.data.zero_()\n    w2.grad.data.zero_()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}