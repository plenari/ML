{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nMulti-GPU examples\n==================\n\n\u6570\u636e\u5e76\u884c\u662f\u6307\u5f53\u6211\u4eec\u5c06 mini-batch \u7684\u6837\u672c\u5206\u6210\u66f4\u5c0f\u7684\nmini-batches, \u5e76\u884c\u5730\u8ba1\u7b97\u6bcf\u4e2a\u66f4\u5c0f\u7684 mini-batches.\n\n\u6570\u636e\u5e76\u884c\u901a\u8fc7\u4f7f\u7528 ``torch.nn.DataParallel`` \u5b9e\u73b0.\n\u6211\u4eec\u53ef\u4ee5\u7528 ``DataParallel`` \u5305\u88c5\u4e00\u4e2a\u6a21\u5757,  \u7136\u540e\u5b83\u5c06\u5728 batch \u7ef4\u5ea6(\u9ed8\u8ba4\u662f0\u8f74)\n\u5e73\u5206\u6570\u636e\u7ed9\u591a\u4e2a GPUs \u8fdb\u884c\u5e76\u884c\u8ba1\u7b97.\n\nDataParallel\n-------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n\n\nclass DataParallelModel(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        self.block1 = nn.Linear(10, 20)\n\n        # \u7528 DataParallel \u5305\u88c5 block2\n        self.block2 = nn.Linear(20, 20)\n        self.block2 = nn.DataParallel(self.block2)\n\n        self.block3 = nn.Linear(20, 20)\n\n    def forward(self, x):\n        x = self.block1(x)\n        x = self.block2(x)\n        x = self.block3(x)\n        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8fd9\u4e2a\u4ee3\u7801\u4e0d\u505a\u4efb\u4f55\u4fee\u6539, \u5728 CPU \u6a21\u5f0f\u4e0b\u4e5f\u80fd\u8fd0\u884c.\n\nDataParallel \u7684\u6587\u6863\u4e3a\n`here <http://pytorch.org/docs/nn.html#torch.nn.DataParallel>`_.\n\n**\u5728\u5176\u4e0a\u5b9e\u73b0 DataParallel \u7684\u57fa\u5143:**\n\n\n\u901a\u5e38, pytorch \u7684 `nn.parallel` \u539f\u51fd\u6570\u53ef\u4ee5\u5355\u72ec\u4f7f\u7528.\n\u6211\u4eec\u5b9e\u73b0\u4e86\u7b80\u5355\u7684\u7c7b\u4f3c MPI \u7684\u539f\u51fd\u6570:\n\n- replicate: \u5728\u591a\u4e2a\u8bbe\u5907\u4e0a\u590d\u5236\u6a21\u5757\n- scatter: \u5728\u7b2c\u4e00\u7ef4\u4e2d\u5206\u914d\u8f93\u5165\n- gather: \u5728\u7b2c\u4e00\u7ef4 gather \u548c concatenate \u8f93\u5165\n- parallel\\_apply: \u5c06\u4e00\u7ec4\u5df2\u7ecf\u5206\u914d\u7684\u8f93\u5165\u5e94\u7528\u4e8e\u4e00\u7ec4\u5df2\u7ecf\u5206\u914d\u7684\u6a21\u578b.\n\n\u4e3a\u4e86\u66f4\u6e05\u6670\u8d77\u89c1, \u8fd9\u91cc\u4f7f\u7528\u8fd9\u4e9b\u96c6\u5408\u7ec4\u6210\u7684\u51fd\u6570 ``data_parallel``\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def data_parallel(module, input, device_ids, output_device=None):\n    if not device_ids:\n        return module(input)\n\n    if output_device is None:\n        output_device = device_ids[0]\n\n    replicas = nn.parallel.replicate(module, device_ids)\n    inputs = nn.parallel.scatter(input, device_ids)\n    replicas = replicas[:len(inputs)]\n    outputs = nn.parallel.parallel_apply(replicas, inputs)\n    return nn.parallel.gather(outputs, output_device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Part of the model on CPU and part on the GPU\n--------------------------------------------\n\n\u8ba9\u6211\u4eec\u6765\u770b\u4e00\u4e2a\u7f51\u7edc\u6a21\u578b, \u4ed6\u7684\u7f51\u7edc\u4e00\u90e8\u5206\u7528 CPU \u8fd0\u7b97, \u53e6\u4e00\u90e8\u5206\u7528 GPU \u8fd0\u7b97. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class DistributedModel(nn.Module):\n\n    def __init__(self):\n        super().__init__(\n            embedding=nn.Embedding(1000, 10),\n            rnn=nn.Linear(10, 10).cuda(0),\n        )\n\n    def forward(self, x):\n        # \u5728 CPU \u4e0a\u8ba1\u7b97 embedding\n        x = self.embedding(x)\n\n        # \u8fc1\u79fb\u5230 GPU\n        x = x.cuda(0)\n\n        # \u5728 GPU \u4e0a\u8fd0\u884c RNN\n        x = self.rnn(x)\n        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8fd9\u662f\u9762\u5411 Torch \u4f7f\u7528\u8005\u7684 PyTorch \u7684\u7b80\u77ed\u4ecb\u7ecd.\n\u5f53\u7136\u8fd8\u6709\u66f4\u591a\u4e1c\u897f\u9700\u8981\u5b66\u4e60.\n\n\u770b\u5b8c\u8fd9\u90e8\u5206\u6559\u7a0b, \u4e5f\u53ef\u4ee5\u770b\u770b\u6211\u4eec\u66f4\u5168\u9762\u7684\u5165\u95e8\u6559\u7a0b, \u5b83\u4ecb\u7ecd\u4e86 ``optim`` package,\ndata loaders \u7b49.: :doc:`/beginner/deep_learning_60min_blitz`.\n\n\u4e5f\u53ef\u4ee5\u770b\u770b\n\n-  :doc:`\u8bad\u7ec3\u4e00\u4e2a\u4f1a\u73a9\u89c6\u9891\u6e38\u620f\u7684\u795e\u7ecf\u7f51\u7edc </intermediate/reinforcement_q_learning>`\n-  `\u4f7f\u7528 imagenet \u56fe\u50cf\u6570\u636e\u6765\u8bad\u7ec3\u4e00\u4e2a\u73b0\u5728\u6700\u70ed\u95e8\u7684\u6a21\u578b <https://github.com/pytorch/examples/tree/master/imagenet>`_\n-  `\u8bad\u7ec3\u4e00\u4e2a GAN \u7f51\u7edc\u6765\u751f\u6210\u4eba\u8138 <https://github.com/pytorch/examples/tree/master/dcgan>`_\n-  `\u4f7f\u7528\u5faa\u73af\u795e\u7ecf\u7f51\u7edc LSTM \u6765\u8bad\u7ec3\u5355\u8bcd\u7ea7\u8bed\u8a00\u6a21\u578b <https://github.com/pytorch/examples/tree/master/word_language_model>`_\n-  `\u4e86\u89e3\u66f4\u591a\u7684\u4f8b\u5b50 <https://github.com/pytorch/examples>`_\n-  `\u4e86\u89e3\u66f4\u591a\u7684\u6559\u7a0b </tutorials>`_\n-  `\u5728\u8bba\u575b\u4e0a\u8ba8\u8bba PyTorch <https://discuss.pytorch.org/>`_\n-  `\u5728 slack \u548c\u5176\u4ed6\u7528\u6237\u8ba8\u8bba PyTorch <http://pytorch.slack.com/messages/beginner/>`_\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}