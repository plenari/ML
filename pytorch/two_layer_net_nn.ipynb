{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nPyTorch: nn\u5305\n-----------\n\n\u672c\u4f8b\u4e2d\u7684\u5168\u8fde\u63a5\u795e\u7ecf\u7f51\u7edc\u6709\u4e00\u4e2a\u9690\u85cf\u5c42, \u540e\u63a5ReLU\u6fc0\u6d3b\u5c42, \u5e76\u4e14\u4e0d\u5e26\u504f\u7f6e\u53c2\u6570. \u8bad\u7ec3\u65f6\u901a\u8fc7\u6700\u5c0f\u5316\u6b27\u5f0f\u8ddd\u79bb\u7684\u5e73\u65b9, \u6765\u5b66\u4e60\u4ecex\u5230y\u7684\u6620\u5c04.\n\n\u5b9e\u73b0\u4e2d\u7528PyTorch\u7684nn\u5305\u6765\u642d\u5efa\u795e\u7ecf\u7f51\u7edc. \u5982\u679c\u4f7f\u7528PyTorch\u7684autograd\u5305, \u5b9a\u4e49\u8ba1\u7b97\u56fe\u548c\u68af\u5ea6\u8ba1\u7b97\u5c06\u53d8\u5f97\u975e\u5e38\u5bb9\u6613.\n\u4f46\u662f\u5bf9\u4e8e\u4e00\u4e9b\u590d\u6742\u7684\u795e\u7ecf\u7f51\u7edc\u6765\u8bf4, \u53ea\u7528autograd\u8fd8\u662f\u6709\u70b9\u5e95\u5c42\u4e86. \u8fd9\u6b63\u662fnn\u5305\u7684\u7528\u6b66\u4e4b\u5730.\nnn\u5305\u5b9a\u4e49\u4e86\u5f88\u591a\u6a21\u5757, \u4f60\u53ef\u4ee5\u628a\u5b83\u4eec\u5f53\u4f5c\u4e00\u4e2a\u4e2a\u7684\u795e\u7ecf\u7f51\u7edc\u5c42. \u6bcf\u4e2a\u6a21\u5757\u90fd\u6709\u8f93\u5165\u8f93\u51fa, \u5e76\u53ef\u80fd\u6709\u4e00\u4e9b\u53ef\u8bad\u7ec3\u6743\u91cd.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom torch.autograd import Variable\n\n# N \u6279\u91cf\u5927\u5c0f; D_in\u662f\u8f93\u5165\u5c3a\u5bf8;\n# H\u662f\u9690\u85cf\u5c3a\u5bf8; D_out\u662f\u8f93\u51fa\u5c3a\u5bf8.\nN, D_in, H, D_out = 64, 1000, 100, 10\n\n# \u521b\u5efa\u968f\u673a\u5f20\u91cf\u6765\u4fdd\u5b58\u8f93\u5165\u548c\u8f93\u51fa,\u5e76\u5c06\u5b83\u4eec\u5305\u88c5\u5728\u53d8\u91cf\u4e2d.\nx = Variable(torch.randn(N, D_in))\ny = Variable(torch.randn(N, D_out), requires_grad=False)\n\n# \u4f7f\u7528nn\u5305\u5c06\u6211\u4eec\u7684\u6a21\u578b\u5b9a\u4e49\u4e3a\u4e00\u7cfb\u5217\u56fe\u5c42. \n# nn.Sequential\u662f\u4e00\u4e2a\u5305\u542b\u5176\u4ed6\u6a21\u5757\u7684\u6a21\u5757,\u5e76\u5c06\u5b83\u4eec\u6309\u987a\u5e8f\u5e94\u7528\u4ee5\u4ea7\u751f\u5176\u8f93\u51fa.\n# \u6bcf\u4e2a\u7ebf\u6027\u6a21\u5757\u4f7f\u7528\u7ebf\u6027\u51fd\u6570\u8ba1\u7b97\u6765\u81ea\u8f93\u5165\u7684\u8f93\u51fa,\u5e76\u4fdd\u5b58\u5185\u90e8\u53d8\u91cf\u7684\u6743\u91cd\u548c\u504f\u5dee.\nmodel = torch.nn.Sequential(\n    torch.nn.Linear(D_in, H),\n    torch.nn.ReLU(),\n    torch.nn.Linear(H, D_out),\n)\n\n# nn\u5305\u8fd8\u5305\u542b\u6d41\u884c\u635f\u5931\u51fd\u6570\u7684\u5b9a\u4e49; \n# \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b,\u6211\u4eec\u5c06\u4f7f\u7528\u5747\u65b9\u5dee(MSE)\u4f5c\u4e3a\u6211\u4eec\u7684\u635f\u5931\u51fd\u6570.\nloss_fn = torch.nn.MSELoss(size_average=False)\n\nlearning_rate = 1e-4\nfor t in range(500):\n    # \u6b63\u5411\u4f20\u9012:\u901a\u8fc7\u5c06x\u4f20\u9012\u7ed9\u6a21\u578b\u6765\u8ba1\u7b97\u9884\u6d4b\u7684y.\n    # \u6a21\u5757\u5bf9\u8c61\u4f1a\u8986\u76d6__call__\u8fd0\u7b97\u7b26,\u56e0\u6b64\u60a8\u53ef\u4ee5\u5c06\u5b83\u4eec\u79f0\u4e3a\u51fd\u6570.\n    # \u8fd9\u6837\u505a\u65f6,\u60a8\u5c06\u8f93\u5165\u6570\u636e\u7684\u53d8\u91cf\u4f20\u9012\u7ed9\u6a21\u5757,\u5e76\u751f\u6210\u8f93\u51fa\u6570\u636e\u7684\u53d8\u91cf.\n    y_pred = model(x)\n\n    # \u8ba1\u7b97\u548c\u6253\u5370\u635f\u5931.\n    # \u6211\u4eec\u4f20\u9012\u5305\u542by\u7684\u9884\u6d4b\u503c\u548c\u771f\u503c\u7684\u53d8\u91cf,\u5e76\u4e14\u635f\u5931\u51fd\u6570\u8fd4\u56de\u5305\u542b\u635f\u5931\u7684\u53d8\u91cf.\n    loss = loss_fn(y_pred, y)\n    print(t, loss.data[0])\n\n    # \u5728\u8fd0\u884c\u53cd\u5411\u4f20\u9012\u4e4b\u524d\u5c06\u68af\u5ea6\u5f52\u96f6.\n    model.zero_grad()\n\n    # \u5411\u540e\u4f20\u9012:\u8ba1\u7b97\u76f8\u5bf9\u4e8e\u6a21\u578b\u7684\u6240\u6709\u53ef\u5b66\u4e60\u53c2\u6570\u7684\u635f\u5931\u68af\u5ea6.\n    # \u5728\u5185\u90e8,\u6bcf\u4e2a\u6a21\u5757\u7684\u53c2\u6570\u90fd\u5b58\u50a8\u5728\u53d8\u91cfrequire_grad = True\u4e2d,\n    # \u56e0\u6b64\u8be5\u8c03\u7528\u5c06\u8ba1\u7b97\u6a21\u578b\u4e2d\u6240\u6709\u53ef\u5b66\u4e60\u53c2\u6570\u7684\u68af\u5ea6.\n    loss.backward()\n\n    # \u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u66f4\u65b0\u6743\u91cd.\n    # \u6bcf\u4e2a\u53c2\u6570\u90fd\u662f\u4e00\u4e2a\u53d8\u91cf,\u6240\u4ee5\u6211\u4eec\u53ef\u4ee5\u50cf\u6211\u4eec\u4ee5\u524d\u90a3\u6837\u8bbf\u95ee\u5b83\u7684\u6570\u636e\u548c\u68af\u5ea6.\n    for param in model.parameters():\n        param.data -= learning_rate * param.grad.data"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}