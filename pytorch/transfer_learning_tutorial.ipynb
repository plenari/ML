{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\u8fc1\u79fb\u5b66\u4e60\u6559\u7a0b\n==========================\n**\u4f5c\u8005**: `Sasank Chilamkurthy <https://chsasank.github.io>`_\n\n\u8fd9\u4e2a\u6559\u7a0b\u5c06\u6559\u4f60\u5982\u4f55\u4f7f\u7528\u8fc1\u79fb\u5b66\u4e60\u8bad\u7ec3\u4f60\u7684\u7f51\u7edc.\n\u4f60\u53ef\u4ee5\u5728 `cs231n \u7b14\u8bb0 <http://cs231n.github.io/transfer-learning/>`__ \u4e2d\n\u9605\u8bfb\u66f4\u591a\u6709\u5173\u8fc1\u79fb\u5b66\u4e60\u7684\u4fe1\u606f.\n\n\u5f15\u7528\u81ea\u8be5\u7b14\u8bb0,\n\n    \u4e8b\u5b9e\u4e0a, \u5f88\u5c11\u6709\u4eba\u4ece\u5934(\u968f\u673a\u521d\u59cb\u5316)\u5f00\u59cb\u8bad\u7ec3\u4e00\u4e2a\u5377\u79ef\u7f51\u7edc, \u56e0\u4e3a\u62e5\u6709\u4e00\u4e2a\u8db3\u591f\u5927\u7684\u6570\u636e\u5e93\u662f\u6bd4\u8f83\u5c11\u89c1\u7684.\n    \u66ff\u4ee3\u7684\u662f, \u901a\u5e38\u4f1a\u4ece\u4e00\u4e2a\u5927\u7684\u6570\u636e\u96c6(\u4f8b\u5982 ImageNet, \u5305\u542b120\u4e07\u7684\u56fe\u7247\u548c1000\u4e2a\u5206\u7c7b)\u9884\u8bad\u7ec3\u4e00\u4e2a\u5377\u79ef\u7f51\u7edc,\n    \u7136\u540e\u5c06\u8fd9\u4e2a\u5377\u79ef\u7f51\u7edc\u4f5c\u4e3a\u521d\u59cb\u5316\u7684\u7f51\u7edc, \u6216\u8005\u662f\u611f\u5174\u8da3\u4efb\u52a1\u7684\u56fa\u5b9a\u7684\u7279\u5f81\u63d0\u53d6\u5668.\n\n\u5982\u4e0b\u662f\u4e24\u79cd\u4e3b\u8981\u7684\u8fc1\u79fb\u5b66\u4e60\u7684\u4f7f\u7528\u573a\u666f:\n\n-  **\u5fae\u8c03\u5377\u79ef\u7f51\u7edc**: \u53d6\u4ee3\u968f\u673a\u521d\u59cb\u5316\u7f51\u7edc, \u6211\u4eec\u4ece\u4e00\u4e2a\u9884\u8bad\u7ec3\u7684\u7f51\u7edc\u521d\u59cb\u5316, \n   \u6bd4\u5982\u4ece imagenet 1000 \u6570\u636e\u96c6\u9884\u8bad\u7ec3\u7684\u7f51\u7edc. \u5176\u4f59\u7684\u8bad\u7ec3\u5c31\u50cf\u5f80\u5e38\u4e00\u6837.\n-  **\u5377\u79ef\u7f51\u7edc\u4f5c\u4e3a\u56fa\u5b9a\u7684\u7279\u5f81\u63d0\u53d6\u5668**: \u5728\u8fd9\u91cc, \u6211\u4eec\u56fa\u5b9a\u7f51\u7edc\u4e2d\u7684\u6240\u6709\u6743\u91cd, \u6700\u540e\u7684\u5168\u8fde\u63a5\u5c42\u9664\u5916.\n   \u6700\u540e\u7684\u5168\u8fde\u63a5\u5c42\u88ab\u65b0\u7684\u968f\u673a\u6743\u91cd\u66ff\u6362, \u5e76\u4e14, \u53ea\u6709\u8fd9\u4e00\u5c42\u662f\u88ab\u8bad\u7ec3\u7684.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# License: BSD\n# Author: Sasank Chilamkurthy\n\nfrom __future__ import print_function, division\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\n\nplt.ion()   # interactive mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u52a0\u8f7d\u6570\u636e\n---------\n\n\u6211\u4eec\u7528 torchvision \u548c torch.utils.data \u5305\u52a0\u8f7d\u6570\u636e.\n\n\u6211\u4eec\u4eca\u5929\u8981\u89e3\u51b3\u7684\u95ee\u9898\u662f, \u8bad\u7ec3\u4e00\u4e2a\u53ef\u4ee5\u533a\u5206 **ants** (\u8682\u8681) \u548c **bees** (\u871c\u8702) \u7684\u6a21\u578b.\n\u7528\u4e8e\u8bad\u7ec3\u7684 ants \u548c bees \u56fe\u7247\u5404120\u5f20. \u6bcf\u4e00\u7c7b\u7528\u4e8e\u9a8c\u8bc1\u7684\u56fe\u7247\u540475\u5f20.\n\u901a\u5e38, \u5982\u679c\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3, \u8fd9\u4e2a\u975e\u5e38\u5c0f\u7684\u6570\u636e\u96c6\u4e0d\u8db3\u4ee5\u8fdb\u884c\u6cdb\u5316.\n\u4f46\u662f, \u56e0\u4e3a\u6211\u4eec\u4f7f\u7528\u8fc1\u79fb\u5b66\u4e60, \u5e94\u8be5\u53ef\u4ee5\u53d6\u5f97\u5f88\u597d\u7684\u6cdb\u5316\u6548\u679c.\n\n\u8fd9\u4e2a\u6570\u636e\u96c6\u662f\u4e00\u4e2a\u975e\u5e38\u5c0f\u7684 imagenet \u5b50\u96c6\n\n.. Note ::\n   \u4ece`\u8fd9\u91cc <https://download.pytorch.org/tutorial/hymenoptera_data.zip>`_ \u4e0b\u8f7d\u6570\u636e, \u7136\u540e\u89e3\u538b\u5230\u5f53\u524d\u76ee\u5f55.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u8bad\u7ec3\u8981\u505a\u6570\u636e\u589e\u5f3a\u548c\u6570\u636e\u6807\u51c6\u5316\n# \u9a8c\u8bc1\u53ea\u505a\u6570\u636e\u6807\u51c6\u5316\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomSizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Scale(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\ndata_dir = 'hymenoptera_data'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train', 'val']}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n                                             shuffle=True, num_workers=4)\n              for x in ['train', 'val']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names = image_datasets['train'].classes\n\nuse_gpu = torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u663e\u793a\u4e00\u4e9b\u56fe\u7247\n^^^^^^^^^^^^^^^^^^^^^^\n\u8ba9\u6211\u4eec\u663e\u793a\u4e00\u4e9b\u8bad\u7ec3\u4e2d\u7684\u56fe\u7247, \u4ee5\u4fbf\u4e86\u89e3\u6570\u636e\u589e\u5f3a.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # \u6682\u505c\u4e00\u4f1a, \u8ba9 plots \u66f4\u65b0\n\n\n# \u83b7\u5f97\u4e00\u6279\u8bad\u7ec3\u6570\u636e\ninputs, classes = next(iter(dataloaders['train']))\n\n# \u4ece\u8fd9\u6279\u6570\u636e\u751f\u6210\u4e00\u4e2a\u65b9\u683c\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8bad\u7ec3\u6a21\u578b\n------------------\n\n\u73b0\u5728, \u8ba9\u6211\u4eec\u5199\u4e00\u4e2a\u901a\u7528\u7684\u51fd\u6570\u6765\u8bad\u7ec3\u6a21\u578b. \u8fd9\u91cc, \u6211\u4eec\u5c06\u4f1a\u4e3e\u4f8b\u8bf4\u660e:\n\n-  \u8c03\u5ea6\u5b66\u4e60\u7387\n-  \u4fdd\u5b58\u6700\u4f73\u7684\u5b66\u4e60\u6a21\u578b\n\n\u4e0b\u9762\u51fd\u6570\u4e2d, ``scheduler`` \u53c2\u6570\u662f ``torch.optim.lr_scheduler`` \u4e2d\u7684 LR scheduler \u5bf9\u8c61.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # \u6bcf\u4e00\u4e2a\u8fed\u4ee3\u90fd\u6709\u8bad\u7ec3\u548c\u9a8c\u8bc1\u9636\u6bb5\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                scheduler.step()\n                model.train(True)  # \u8bbe\u7f6e model \u4e3a\u8bad\u7ec3 (training) \u6a21\u5f0f\n            else:\n                model.train(False)  # \u8bbe\u7f6e model \u4e3a\u8bc4\u4f30 (evaluate) \u6a21\u5f0f\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # \u904d\u5386\u6570\u636e\n            for data in dataloaders[phase]:\n                # \u83b7\u53d6\u8f93\u5165\n                inputs, labels = data\n\n                # \u7528 Variable \u5305\u88c5\u8f93\u5165\u6570\u636e\n                if use_gpu:\n                    inputs = Variable(inputs.cuda())\n                    labels = Variable(labels.cuda())\n                else:\n                    inputs, labels = Variable(inputs), Variable(labels)\n\n                # \u8bbe\u7f6e\u68af\u5ea6\u53c2\u6570\u4e3a 0\n                optimizer.zero_grad()\n\n                # \u6b63\u5411\u4f20\u9012\n                outputs = model(inputs)\n                _, preds = torch.max(outputs.data, 1)\n                loss = criterion(outputs, labels)\n\n                # \u5982\u679c\u662f\u8bad\u7ec3\u9636\u6bb5, \u5411\u540e\u4f20\u9012\u548c\u4f18\u5316\n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n\n                # \u7edf\u8ba1\n                running_loss += loss.data[0] * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # \u6df1\u62f7\u8d1d model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # \u52a0\u8f7d\u6700\u4f73\u6a21\u578b\u7684\u6743\u91cd\n    model.load_state_dict(best_model_wts)\n    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u663e\u793a\u6a21\u578b\u7684\u9884\u6d4b\u7ed3\u679c\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\u5199\u4e00\u4e2a\u5904\u7406\u5c11\u91cf\u56fe\u7247, \u5e76\u663e\u793a\u9884\u6d4b\u7ed3\u679c\u7684\u901a\u7528\u51fd\u6570\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def visualize_model(model, num_images=6):\n    images_so_far = 0\n    fig = plt.figure()\n\n    for i, data in enumerate(dataloaders['val']):\n        inputs, labels = data\n        if use_gpu:\n            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n        else:\n            inputs, labels = Variable(inputs), Variable(labels)\n\n        outputs = model(inputs)\n        _, preds = torch.max(outputs.data, 1)\n\n        for j in range(inputs.size()[0]):\n            images_so_far += 1\n            ax = plt.subplot(num_images//2, 2, images_so_far)\n            ax.axis('off')\n            ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n            imshow(inputs.cpu().data[j])\n\n            if images_so_far == num_images:\n                return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8c03\u6574\u5377\u79ef\u7f51\u7edc\n----------------------\n\n\u52a0\u8f7d\u4e00\u4e2a\u9884\u8bad\u7ec3\u7684\u7f51\u7edc, \u5e76\u91cd\u7f6e\u6700\u540e\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_ft = models.resnet18(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\nmodel_ft.fc = nn.Linear(num_ftrs, 2)\n\nif use_gpu:\n    model_ft = model_ft.cuda()\n\ncriterion = nn.CrossEntropyLoss()\n\n# \u5982\u4f60\u6240\u89c1, \u6240\u6709\u53c2\u6570\u90fd\u5c06\u88ab\u4f18\u5316\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n\n# \u6bcf 7 \u4e2a\u8fed\u4ee3, \u8ba9 LR \u8870\u51cf 0.1 \u56e0\u7d20\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8bad\u7ec3\u548c\u8bc4\u4f30\n^^^^^^^^^^^^^^^^^^\n\n\u5982\u679c\u4f7f\u7528 CPU, \u8fd9\u5c06\u82b1\u8d39 15-25 \u5206\u949f. \u4f46\u4f7f\u7528 GPU \u7684\u8bdd, \u9700\u8981\u7684\u65f6\u95f4\u5c06\u5c11\u4e8e1\u5206\u949f.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n                       num_epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "visualize_model(model_ft)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5377\u79ef\u7f51\u7edc\u4f5c\u4e3a\u56fa\u5b9a\u7684\u7279\u5f81\u63d0\u53d6\u5668\n----------------------------------\n\n\u8fd9\u91cc, \u6211\u4eec\u56fa\u5b9a\u7f51\u7edc\u4e2d\u9664\u6700\u540e\u4e00\u5c42\u5916\u7684\u6240\u6709\u6743\u91cd. \u4e3a\u4e86\u56fa\u5b9a\u8fd9\u4e9b\u53c2\u6570, \u6211\u4eec\u9700\u8981\u8bbe\u7f6e ``requires_grad == False`` ,\n\u7136\u540e\u5728 ``backward()`` \u4e2d\u5c31\u4e0d\u4f1a\u8ba1\u7b97\u68af\u5ea6.\n\n\u4f60\u53ef\u4ee5\u5728 `\u8fd9\u91cc <http://pytorch.org/docs/notes/autograd.html#excluding-subgraphs-from-backward>`__ \u9605\u8bfb\u66f4\u591a\u76f8\u5173\u4fe1\u606f.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_conv = torchvision.models.resnet18(pretrained=True)\nfor param in model_conv.parameters():\n    param.requires_grad = False\n\n# \u65b0\u6784\u5efa\u7684 module \u7684\u53c2\u6570\u4e2d, \u9ed8\u8ba4\u8bbe\u7f6e\u4e86 requires_grad=True.\nnum_ftrs = model_conv.fc.in_features\nmodel_conv.fc = nn.Linear(num_ftrs, 2)\n\nif use_gpu:\n    model_conv = model_conv.cuda()\n\ncriterion = nn.CrossEntropyLoss()\n\n# \u5982\u4f60\u6240\u89c1, \u548c\u6211\u4eec\u524d\u9762\u63d0\u51fa\u7684\u4e00\u6837, \u53ea\u6709\u6700\u540e\u4e00\u5c42\u7684\u53c2\u6570\u88ab\u4f18\u5316.\noptimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n\n# \u6bcf 7 \u4e2a\u8fed\u4ee3, \u8ba9 LR \u8870\u51cf 0.1 \u56e0\u7d20\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8bad\u7ec3\u548c\u8bc4\u4f30\n^^^^^^^^^^^^^^^^^^\n\n\u5728\u4f7f\u7528 CPU \u7684\u60c5\u51b5\u4e0b, \u548c\u524d\u4e00\u4e2a\u65b9\u6848\u76f8\u6bd4, \u8fd9\u5c06\u82b1\u8d39\u7684\u65f6\u95f4\u662f\u5b83\u7684\u4e00\u534a.\n\u671f\u671b\u4e2d, \u7f51\u7edc\u7684\u5927\u90e8\u5206\u662f\u4e0d\u9700\u8981\u8ba1\u7b97\u68af\u5ea6\u7684. \u524d\u5411\u4f20\u9012\u4f9d\u7136\u8981\u8ba1\u7b97\u68af\u5ea6.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n                         exp_lr_scheduler, num_epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "visualize_model(model_conv)\n\nplt.ioff()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}