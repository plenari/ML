{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\u57fa\u4e0e\u5b57\u7b26\u7ea7RNN\uff08Char-RNN\uff09\u7684\u4eba\u540d\u751f\u6210\n*******************************************\n**\u4f5c\u8005**: `Sean Robertson <https://github.com/spro/practical-pytorch>`_\n\n\u5728 :doc:`\u4e0a\u4e00\u4e2a\u6559\u7a0b </intermediate/char_rnn_classification_tutorial>` \n\u91cc\u6211\u4eec\u4f7f\u7528RNN\u628a\u540d\u5b57\u5206\u7c7b\u5230\u5b83\u6240\u5c5e\u7684\u8bed\u8a00\u4e2d, \u8fd9\u6b21\u6211\u4eec\u6539\u53d8\u4e00\u4e0b\u6765\u5b66\u4e60\u4ece\u8bed\u8a00\u4e2d\u751f\u6210\u540d\u5b57. \n\n::\n\n    > python sample.py Russian RUS\n    Rovakov\n    Uantov\n    Shavakov\n\n    > python sample.py German GER\n    Gerren\n    Ereng\n    Rosher\n\n    > python sample.py Spanish SPA\n    Salla\n    Parer\n    Allan\n\n    > python sample.py Chinese CHI\n    Chan\n    Hang\n    Iun\n\n\u6211\u4eec\u4ecd\u7136\u624b\u5de5\u642d\u5efa\u4e00\u4e2a\u5305\u542b\u51e0\u4e2a\u7ebf\u6027\u5c42\u7684\u5c0f\u7684RNN. \u8fd9\u6b21\u7684\u6700\u5927\u7684\u4e0d\u540c\u662f\u8f93\u5165\u4e00\u4e2a\u7c7b\u522b, \u6bcf\u6b21\u8f93\u51fa\u4e00\u4e2a\u5b57\u6bcd, \n\u800c\u4e0d\u662f\u8bfb\u5165\u6240\u6709\u540d\u5b57\u7684\u5b57\u6bcd\u6765\u9884\u6d4b\u4e00\u4e2a\u7c7b\u522b. \u5faa\u73af\u7684\u9884\u6d4b\u6bcf\u4e00\u4e2a\u5b57\u6bcd\u6765\u6784\u6210\u8bed\u8a00\uff08\u4e5f\u53ef\u4ee5\u7528\u6587\n\u5b57\u6216\u8005\u5176\u4ed6\u66f4\u9ad8\u7ea7\u7684\u7ed3\u6784\u5b8c\u6210\uff09, \u901a\u5e38\u88ab\u79f0\u4e3a\u201c\u8bed\u8a00\u6a21\u578b\u201d. \n\n**\u63a8\u8350\u9605\u8bfb: **\n\n\u5047\u8bbe\u4f60\u81f3\u5c11\u5b89\u88c5\u4e86PyTorch, \u719f\u6089Python, \u7406\u89e3Tensors: \n\n-  http://pytorch.org/ : \u5b89\u88c5\u8bf4\u660e\n-  :doc:`/beginner/deep_learning_60min_blitz` \u83b7\u53d6\u4e00\u822c\u7684 PyTorch \u5165\u95e8\n-  :doc:`/beginner/pytorch_with_examples` \u5e7f\u6cdb\u4e14\u6df1\u5165\u7684\u6982\u8ff0\n-  :doc:`/beginner/former_torchies_tutorial` \u5982\u679c\u66fe\u7ecf\u662f Lua Torch \u7684\u7528\u6237\n\n\u4e0b\u9762\u8fd9\u4e9b\u5bf9\u4e86\u89e3 RNNs \u548c\u5176\u5de5\u4f5c\u539f\u7406\u4e5f\u662f\u5f88\u6709\u7528\u7684: \n\n-  `The Unreasonable Effectiveness of Recurrent Neural\n   Networks <http://karpathy.github.io/2015/05/21/rnn-effectiveness/>`__\n   \u5c55\u793a\u4e86\u4e00\u7cfb\u5217\u771f\u5b9e\u751f\u6d3b\u4e2d\u7684\u4f8b\u5b50\n-  `Understanding LSTM\n   Networks <http://colah.github.io/posts/2015-08-Understanding-LSTMs/>`__\n   \u662f\u4e00\u7bc7\u7279\u522b\u5173\u4e8eLSTMs\u7684\u6587\u7ae0, \u4f46\u662f\u5bf9\u4e8e\u4e00\u822c\u7684RNNs\u4e5f\u5f88\u6709\u76ca\u7684\n\n\u8fd8\u5efa\u8bae\u4e0a\u4e00\u4e2a\u6559\u7a0b:  :doc:`/intermediate/char_rnn_classification_tutorial`\n\n\n\u6570\u636e\u51c6\u5907\n==================\n\n.. Note::\n   \u4ece `\u8fd9\u91cc <https://download.pytorch.org/tutorial/data.zip>`_\n   \u4e0b\u8f7d\u6570\u636e, \u5e76\u89e3\u538b\u5230\u5f53\u524d\u76ee\u5f55. \n\n\u66f4\u591a\u7684\u7ec6\u8282\u53c2\u8003\u4e0a\u4e00\u4e2a\u6559\u7a0b, \u603b\u4e4b, \u6570\u636e\u542b\u6709\u4e00\u6279\u7eaf\u6587\u672c\u6587\u4ef6:  ``data/names/[Language].txt`` \n\u6bcf\u4e00\u884c\u4e00\u4e2a\u4eba\u540d. \u5c06\u884c\u5206\u5272\u6210\u6570\u7ec4, \u5e76\u628a Unicode \u8f6c\u6362\u6210 ASCII \u7f16\u7801, \u6700\u540e\u653e\u8fdb\u4e00\u4e2a\u5b57\u5178\u91cc ``{language: [names ...]}``. \n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\nfrom io import open\nimport glob\nimport unicodedata\nimport string\n\nall_letters = string.ascii_letters + \" .,;'-\"\nn_letters = len(all_letters) + 1 # \u6dfb\u52a0 EOS \u6807\u8bb0\n\ndef findFiles(path): return glob.glob(path)\n\n# \u5c06 Unicode \u5b57\u7b26\u4e32\u8f6c\u6362\u4e3a\u7eaf ASCII \u7f16\u7801, \u611f\u8c22 http://stackoverflow.com/a/518232/2809427\ndef unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n        and c in all_letters\n    )\n\n# \u8bfb\u53d6\u6587\u4ef6\u5e76\u5206\u5272\u6210\u884c\ndef readLines(filename):\n    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n    return [unicodeToAscii(line) for line in lines]\n\n# \u6784\u5efa\u6620\u5c04\u5b57\u5178 category_lines , \u6bcf\u4e2a\u7c7b\u522b\u662f\u7531\u5f88\u591a\u4e2a\u884c\u7ec4\u6210\u7684list\ncategory_lines = {}\nall_categories = []\nfor filename in findFiles('data/names/*.txt'):\n    category = filename.split('/')[-1].split('.')[0]\n    all_categories.append(category)\n    lines = readLines(filename)\n    category_lines[category] = lines\n\nn_categories = len(all_categories)\n\nprint('# categories:', n_categories, all_categories)\nprint(unicodeToAscii(\"O'N\u00e9\u00e0l\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u521b\u5efa\u7f51\u7edc\n====================\n\n \u8fd9\u4e2a\u7f51\u7edc\u6269\u5c55\u4e86 `\u4e0a\u4e00\u4e2a\u6559\u7a0b\u7684RNN <http://pytorch.apachecn.org/cn/tutorials/intermediate/char_rnn_classification_tutorial.html>`__ , \u4e3a\u7c7b\u522b\u5f20\u91cf\u6dfb\u52a0\u4e86\u4e00\u4e2a\u989d\u5916\u7684\u53c2\u6570, \u5e76\u548c\u5176\u4ed6\u7684\u53c2\u6570\u4e32\u8054\u5728\u4e00\u8d77. \u7c7b\u522b\u5f20\u91cf\n\u548c\u5b57\u6bcd\u7684\u8f93\u5165\u4e00\u6837\u662f one-hot \u5411\u91cf. \n\n\u6211\u4eec\u5c06\u8f93\u51fa\u89e3\u91ca\u6210\u4e3a\u4e0b\u4e00\u4e2a\u5b57\u6bcd\u7684\u6982\u7387, \u91c7\u6837\u7684\u65f6\u5019, \u6700\u6709\u53ef\u80fd\u7684\u8f93\u51fa\u88ab\u5f53\u505a\u4e0b\u4e00\u4e2a\u8f93\u5165. \n\n\u4e3a\u4e86\u8ba9\u7f51\u7edc\u66f4\u52a0\u6709\u6548\u5de5\u4f5c, \u6211\u6dfb\u52a0\u4e86\u7b2c\u4e8c\u4e2a\u7ebf\u6027\u5c42 ``o2o`` \uff08\u5728\u5408\u5e76\u4e86\u9690\u85cf\u5c42\u548c\u8f93\u51fa\u5c42\u7684\u540e\u9762\uff09. \n\u8fd8\u6709\u4e00\u4e2a Dropout \u5c42,  `\u4f7f\u8f93\u5165\u7684\u90e8\u5206\u503c\u4ee5\u7ed9\u5b9a\u7684\u6982\u7387\u503c\u968f\u673a\u7684\u53d8\u6210 0 <https://arxiv.org/abs/1207.0580>`__ \n\uff08\u8fd9\u91cc\u6982\u7387\u53d60.1\uff09, \u8fd9\u6837\u505a\u901a\u5e38\u662f\u4e3a\u4e86\u6a21\u7cca\u8f93\u5165\u4ee5\u9632\u6b62\u8fc7\u62df\u5408. \u8fd9\u91cc\u6211\u4eec\u5728\u7f51\u7edc\u7684\u6700\u672b\u7aef\u4f7f\u7528\u5b83, \u4ece\u800c\u6545\u610f\u6dfb\u52a0\u4e00\u4e9b\u6df7\u4e71\u548c\u589e\u52a0\u91c7\u6837\u7684\u591a\u6837\u5316. \n\n.. figure:: https://i.imgur.com/jzVrf7f.png\n   :alt:\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nclass RNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(RNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size)\n        self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size)\n        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n        self.dropout = nn.Dropout(0.1)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, category, input, hidden):\n        input_combined = torch.cat((category, input, hidden), 1)\n        hidden = self.i2h(input_combined)\n        output = self.i2o(input_combined)\n        output_combined = torch.cat((hidden, output), 1)\n        output = self.o2o(output_combined)\n        output = self.dropout(output)\n        output = self.softmax(output)\n        return output, hidden\n\n    def initHidden(self):\n        return Variable(torch.zeros(1, self.hidden_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8bad\u7ec3\n=========\n\u8bad\u7ec3\u524d\u7684\u51c6\u5907\n----------------------\n\n\u9996\u5148, \u5229\u7528\u8f85\u52a9\u51fd\u6570\u4ea7\u751f\u968f\u673a\u7684\uff08category, line\uff09\u5bf9: \n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import random\n\n# \u4ecelist\u4e2d\u968f\u673a\u9009\u53d6\u9879\ndef randomChoice(l):\n    return l[random.randint(0, len(l) - 1)]\n\n# \u83b7\u53d6\u968f\u673a\u7684\u7c7b\u522b\u548c\u8be5\u7c7b\u522b\u4e2d\u968f\u673a\u7684\u884c\ndef randomTrainingPair():\n    category = randomChoice(all_categories)\n    line = randomChoice(category_lines[category])\n    return category, line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5bf9\u6bcf\u4e00\u4e2a\u65f6\u95f4\u70b9\uff08\u4e5f\u5c31\u662f\u8bf4\u5728\u8bad\u7ec3\u96c6\u4e2d\u8bcd\u7684\u6bcf\u4e2a\u5b57\u6bcd\uff09\u7f51\u7edc\u7684\u8f93\u5165\u662f ``(\u7c7b\u522b, \u5f53\u524d\u5b57\u6bcd, \u9690\u85cf\u5c42\u72b6\u6001)`` , \n\u8f93\u51fa\u662f ``(\u4e0b\u4e00\u4e2a\u5b57\u6bcd, \u4e0b\u4e00\u4e2a\u9690\u85cf\u5c42\u72b6\u6001)`` . \u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u8bad\u7ec3\u96c6, \u6211\u4eec\u9700\u8981\u7684\u662f\u7c7b\u522b\u3001\u8f93\u5165\u7684\u5b57\u6bcd\u96c6\u3001\u8f93\u51fa/\u76ee\u6807\u5b57\u6bcd\u96c6. \n\n\u56e0\u4e3a\u5728\u6bcf\u4e00\u6b65, \u6211\u4eec\u4ece\u5f53\u524d\u7684\u5b57\u6bcd\u9884\u6d4b\u4e0b\u4e00\u4e2a\u5b57\u6bcd, \u8fd9\u6837\u7684\u5b57\u6bcd\u5bf9\u662f\u5728\u539f\u6709\u884c\u4e2d\u8fde\u7eed\u5b57\u6bcd\u7684\u96c6\u5408, \n\u4f8b\u5982, \u5bf9\u4e8e ``\"ABCD<EOS>\"`` \u5c06\u4f1a\u4ea7\u751f (\"A\", \"B\"), (\"B\", \"C\"),\n(\"C\", \"D\"), (\"D\", \"EOS\"). \n\n.. figure:: https://i.imgur.com/JH58tXY.png\n   :alt:\n\n\u7c7b\u522b\u5f20\u91cf\u662f\u4e00\u4e2a\u5927\u5c0f\u4e3a ``<1 x n_categories>`` \u7684 `one-hot\ntensor <https://en.wikipedia.org/wiki/One-hot>`__ \u5f20\u91cf, \n\u5728\u8bad\u7ec3\u7684\u6bcf\u4e00\u4e2a\u65f6\u95f4\u70b9\u628a\u5b83\u5582\u7ed9\u7f51\u7edc \u2014\u2014 \u8fd9\u662f\u4e00\u4e2a\u8bbe\u8ba1\u7684\u9009\u62e9, \u5b83\u53ef\u4ee5\u88ab\u5f53\u4f5c\u4e3a\u521d\u59cb\u9690\u85cf\u72b6\u6216\u5176\u4ed6\u7b56\u7565\u7684\u4e00\u90e8\u5206. \n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u7c7b\u522b\u7684 one-hot \u5411\u91cf\ndef categoryTensor(category):\n    li = all_categories.index(category)\n    tensor = torch.zeros(1, n_categories)\n    tensor[0][li] = 1\n    return tensor\n\n# \u8f93\u5165\u4e32\u4ece\u7b2c\u4e00\u4e2a\u5b57\u6bcd\u5230\u6700\u540e\u4e00\u4e2a\u5b57\u6bcd\uff08\u4e0d\u5305\u62ec EOS \uff09\u7684 one-hot \u77e9\u9635\ndef inputTensor(line):\n    tensor = torch.zeros(len(line), 1, n_letters)\n    for li in range(len(line)):\n        letter = line[li]\n        tensor[li][0][all_letters.find(letter)] = 1\n    return tensor\n\n# \u76ee\u6807\u7684\u7b2c\u4e8c\u4e2a\u5b57\u6bcd\u5230\u7ed3\u5c3e\uff08EOS\uff09\u7684 LongTensor \ndef targetTensor(line):\n    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n    letter_indexes.append(n_letters - 1) # EOS\n    return torch.LongTensor(letter_indexes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u4e3a\u4e86\u8bad\u7ec3\u8fc7\u7a0b\u7684\u4fbf\u5229, \u6dfb\u52a0\u4e00\u4e2a ``randomTrainingExample`` \u51fd\u6570, \u83b7\u53d6\u968f\u673a\u7684 (category, line) \u5bf9, \n\u5e76\u628a\u4ed6\u4eec\u8f6c\u6362\u6210\u9700\u8981\u7684 (category, input, target) \u5f20\u91cf. \n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u4ece\u968f\u673a\u7684\uff08category, line\uff09\u5bf9\u4e2d\u751f\u6210 category, input, and target \u5f20\u91cf \ndef randomTrainingExample():\n    category, line = randomTrainingPair()\n    category_tensor = Variable(categoryTensor(category))\n    input_line_tensor = Variable(inputTensor(line))\n    target_line_tensor = Variable(targetTensor(line))\n    return category_tensor, input_line_tensor, target_line_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u7f51\u7edc\u7684\u8bad\u7ec3\n--------------------\n\n\u4e0e\u5206\u7c7b\u76f8\u6bd4, \u5206\u7c7b\u53ea\u7528\u5230\u4e86\u6700\u540e\u7684\u8f93\u51fa, \u800c\u8fd9\u91cc\u6bcf\u4e2a\u6b65\u90fd\u4f1a\u4ea7\u751f\u4e00\u4e2a\u9884\u6d4b, \u6240\u4ee5\u6211\u4eec\u9700\u8981\u8ba1\u7b97\u6bcf\u4e00\u6b65\u7684\u635f\u5931. \n\n\u81ea\u52a8\u6c42\u5bfc\uff08autograd\uff09\u7684\u9b54\u529b\u5c31\u5728\u4e8e, \u5b83\u5141\u8bb8\u5c06\u6bcf\u4e00\u6b65\u7684\u635f\u5931\u7b80\u5355\u7684\u52a0\u548c, \u5e76\u5728\u6700\u540e\u8c03\u7528 backward \n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "criterion = nn.NLLLoss()\n\nlearning_rate = 0.0005\n\ndef train(category_tensor, input_line_tensor, target_line_tensor):\n    hidden = rnn.initHidden()\n\n    rnn.zero_grad()\n\n    loss = 0\n\n    for i in range(input_line_tensor.size()[0]):\n        output, hidden = rnn(category_tensor, input_line_tensor[i], hidden)\n        loss += criterion(output, target_line_tensor[i])\n\n    loss.backward()\n\n    for p in rnn.parameters():\n        p.data.add_(-learning_rate, p.grad.data)\n\n    return output, loss.data[0] / input_line_tensor.size()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u4e3a\u4e86\u8ddf\u8e2a\u8bad\u7ec3\u82b1\u8d39\u4e86\u591a\u957f\u65f6\u95f4, \u8fd9\u91cc\u6dfb\u52a0\u4e00\u4e2a ``timeSince(timestamp)`` \u51fd\u6570, \u8fd4\u56de\u4e00\u4e2a\u4eba\u4eec\u6613\u8bfb\u7684\u5b57\u7b26\u4e32: \n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\nimport math\n\ndef timeSince(since):\n    now = time.time()\n    s = now - since\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8bad\u7ec3\u548c\u5f80\u5e38\u4e00\u6837, \u4e0d\u505c\u7684\u8c03\u7528 train \u5e76\u7b49\u5f85\u4e00\u4f1a, \u6253\u5370\u5f53\u524d\u65f6\u95f4, \u6bcf\u9694 ``print_every`` \n\u4e2a\u4f8b\u5b50\u6253\u5370 loss, \u5c06\u6bcf ``plot_every`` \u4e2a\u4f8b\u5b50\u7684\u5e73\u5747\u635f\u5931\u4fdd\u5b58\u5728 ``all_losses`` \u4e2d\u4ee5\u4fbf\u540e\u9762\u753b\u56fe. \n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rnn = RNN(n_letters, 128, n_letters)\n\nn_iters = 100000\nprint_every = 5000\nplot_every = 500\nall_losses = []\ntotal_loss = 0 # \u6bcf plot_every \u6b21\u8fed\u4ee3\u9700\u8981\u91cd\u7f6e\n\nstart = time.time()\n\nfor iter in range(1, n_iters + 1):\n    output, loss = train(*randomTrainingExample())\n    total_loss += loss\n\n    if iter % print_every == 0:\n        print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n\n    if iter % plot_every == 0:\n        all_losses.append(total_loss / plot_every)\n        total_loss = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u7ed8\u5236\u635f\u5931\n-------------------\n\n\u4ece all\\_losses \u4e2d\u7ed8\u5236\u5386\u53f2\u635f\u5931, \u4ee5\u5c55\u73b0\u7f51\u7edc\u7684\u5b66\u4e60\u8fc7\u7a0b\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\nplt.figure()\nplt.plot(all_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u7f51\u7edc\u91c7\u6837\n====================\n\n\u4e3a\u4e86\u91c7\u6837, \u6211\u4eec\u7ed9\u7f51\u7edc\u4e00\u4e2a\u5b57\u6bcd\u5e76\u95ee\u4e0b\u4e00\u4e2a\u5b57\u6bcd\u662f\u4ec0\u4e48, \u91cd\u590d\u8fd9\u4e2a\u8fc7\u7a0b\u76f4\u5230 EOS \u6807\u8bb0. \n\n-  \u521b\u5efa\u8f93\u5165\u7c7b\u522b\u3001\u8d77\u59cb\u5b57\u6bcd\u548c\u9690\u85cf\u5c42\u72b6\u6001\u7684\u5f20\u91cf\n-  \u521b\u5efa\u4e00\u4e2a\u5e26\u6709\u8d77\u59cb\u5b57\u6bcd\u7684 ``output_name`` \u4e32\n-  \u76f4\u5230\u6700\u5927\u7684\u8f93\u51fa\u957f\u5ea6, \n\n   -  \u5f53\u524d\u5b57\u6bcd\u5582\u7ed9\u7f51\u7edc\n   -  \u4ece\u6700\u9ad8\u7684\u8f93\u51fa\u83b7\u53d6\u4e0b\u4e00\u4e2a\u5b57\u6bcd\u548c\u4e0b\u4e00\u4e2a\u9690\u85cf\u5c42\u72b6\u6001\n   -  \u5982\u679c\u8f93\u51fa\u5b57\u6bcd\u662f EOS, \u7b97\u6cd5\u7ed3\u675f\n   -  \u5982\u679c\u8f93\u51fa\u662f\u5e38\u89c4\u5b57\u6bcd, \u5c06\u5176\u52a0\u5165\u5230 ``output_name`` \u5e76\u7ee7\u7eed\n\n-  \u8fd4\u56de\u6700\u7ec8\u7684\u540d\u5b57\n\n.. Note::\n   \u4e0e\u7ed9\u5b9a\u8d77\u59cb\u5b57\u6bcd\u4e0d\u540c\u7684\u662f, \u6709\u5176\u4ed6\u7684\u7b56\u7565\u662f\u5728\u8bad\u7ec3\u7684\u65f6\u5019\u5305\u542b\u4e00\u4e2a\u201c\u4e32\u8d77\u59cb\u201d\u6807\u8bb0, \u8ba9\u7f51\u7edc\u9009\u62e9\u5c5e\u4e8e\u81ea\u5df1\u7684\u8d77\u59cb\u5b57\u6bcd. \n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "max_length = 20\n\n# \u4ece\u7c7b\u522b\u548c\u8d77\u59cb\u5b57\u6bcd\u91c7\u6837\ndef sample(category, start_letter='A'):\n    category_tensor = Variable(categoryTensor(category))\n    input = Variable(inputTensor(start_letter))\n    hidden = rnn.initHidden()\n\n    output_name = start_letter\n\n    for i in range(max_length):\n        output, hidden = rnn(category_tensor, input[0], hidden)\n        topv, topi = output.data.topk(1)\n        topi = topi[0][0]\n        if topi == n_letters - 1:\n            break\n        else:\n            letter = all_letters[topi]\n            output_name += letter\n        input = Variable(inputTensor(letter))\n\n    return output_name\n\n# \u7ed9\u5b9a\u4e00\u4e2a\u7c7b\u522b\u548c\u591a\u4e2a\u8d77\u59cb\u5b57\u6bcd \u83b7\u53d6\u4e2a\u91c7\u6837\u7ed3\u679c\ndef samples(category, start_letters='ABC'):\n    for start_letter in start_letters:\n        print(sample(category, start_letter))\n\nsamples('Russian', 'RUS')\n\nsamples('German', 'GER')\n\nsamples('Spanish', 'SPA')\n\nsamples('Chinese', 'CHI')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u7ec3\u4e60\n=========\n\n-  \u5c1d\u8bd5\u4f7f\u7528\u4e0d\u540c \u7c7b\u522b->\u884c \u6570\u636e\u96c6, \u4f8b\u5982: \n\n   -  \u5c0f\u8bf4\u7cfb\u5217 -> \u89d2\u8272\u540d\u5b57\n   -  \u8bcd\u6027 -> \u8bcd\u8bed\n   -  \u56fd\u5bb6 -> \u57ce\u5e02\n\n-  \u4f7f\u7528\u201c\u4e32\u8d77\u59cb\u201d\u6807\u8bb0, \u4f7f\u91c7\u6837\u7684\u65f6\u5019\u4e0d\u7528\u7ed9\u5b9a\u8d77\u59cb\u5b57\u6bcd\n-  \u4f7f\u7528\u66f4\u5927\u548c/\u6216\u66f4\u597d\u7684\u7f51\u7edc\u7ed3\u6784\u83b7\u53d6\u66f4\u597d\u7684\u7ed3\u679c\n\n   -  \u5c1d\u8bd5\u4e00\u4e0b nn.LSTM \u548c nn.GRU \u5c42\n   -  \u5c06\u8fd9\u4e9b RNNs \u7ec4\u5408\u6210\u66f4\u9ad8\u7ea7\u7684\u7f51\u7edc\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}