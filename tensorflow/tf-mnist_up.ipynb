{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深入mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InteractiveSession(),交互环境的简便方法，使用起来总是出错。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "isess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " |  The methods @{tf.Tensor.eval}\n",
    " |  and @{tf.Operation.run}\n",
    " |  will use that session to run ops."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test=tf.constant([1,2,3],name='test')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test.eval()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test2=tf.Variable(test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.global_variables_initializer().run()\n",
    "test2.eval()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "type(tf.global_variables_initializer)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "isess.close()\n",
    "#不知道为什么关也关不掉！！！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置变量（需要优化的参数），占位符（需要传入的数据）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess=tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", shape=[None, 784])\n",
    "y_ = tf.placeholder(\"float\", shape=[None, 10])#labels y_\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积神经网络理解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN的基本配置---卷积层、Relu层、池化层，全连接。\n",
    "##### 1，conv,卷积计算层，线性计算\n",
    "首先对图片数据，找feature，即卷积核。因为样本是二维数据，一般选用3x3,5x5.对于二维数据来说主要设定好三个方向的步进就够{左右方向，上下方向，样本间距？}，对于三维数据多一个feature 步进。如果步进较大可以缩小数据总量。计算出来的新的数据叫：feature map,是已经提取出来的特征，feature map 值越大feature越有意义。\n",
    "###### 注意：可以选择多个feature（channel?）\n",
    "#####  2，激活层\n",
    "方法很多，有logistics函数，tanh和Relu函数。主要作用就是就是对上一步计算结果feature map 进行筛选。非线性激活函数Relu:f(x)=max(0,x)。\n",
    "##### 3，池化层\n",
    "对激活层的结果处理。Max Pooling 最大池化、Average Pooling平均池化。选择池化尺寸为2x2，对于max pooling 就是选择这个范围内最大的值当做这个范围的值。\n",
    "##### 4，全连接。\n",
    "将筛选后的特征送给分类器，这个时候还需要把四个维度的数据转成二维的>>>样本数X特征数。\n",
    "###### end，这是对图像的处理，如果对其他样本本来就不是二维数据的情形呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### help(tf.truncated_normal)\n",
    "truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
    "    \n",
    "    Outputs random values from a truncated normal distribution.\n",
    "    \n",
    "    The generated values follow a normal distribution with specified mean and\n",
    "    standard deviation, except that values whose magnitude is more than 2 standard\n",
    "    deviations from the mean are dropped and re-picked.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1,权重初始化，加入少量的噪声来打破对称性以及避免0梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    我们的卷积使用1步长（stride size），0边距（padding size）的模板，保证输出和输入是同一个大小。\n",
    "    我们的池化用简单传统的2x2大小的模板做max pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2，定义卷积和池化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conv2d(input, filter, strides, padding, use_cudnn_on_gpu=True, data_format='NHWC', name=None)[num,high,width,channel]\n",
    "    Computes a 2-D convolution given 4-D `input` and `filter` tensors.    \n",
    "##### input: A `Tensor`. Must be one of the following types: `half`, `float32`.format,[batch, in_height, in_width, in_channels]\n",
    "        A 4-D tensor. The dimension order is interpreted according to the value\n",
    "        of `data_format`, see below for details.\n",
    "##### filter: A `Tensor`. Must have the same type as `input`.\n",
    "        `[filter_height, filter_width, in_channels, out_channels]`\n",
    "##### strides: A list of `ints`.\n",
    "      1-D tensor of length 4.  The stride of the sliding window for each\n",
    "        dimension of `input`. The dimension order is determined by the value of\n",
    "          `data_format`, see below for details.\n",
    " ##### padding: A `string` from: `\"SAME\", \"VALID\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max_pool(value, ksize, strides, padding, data_format='NHWC', name=None),\n",
    "\n",
    "##### ksize: A 1-D int Tensor of 4 elements.  \n",
    "    The size of the window for each dimension of the input tensor.\n",
    "#####  strides: A 1-D int Tensor of 4 elements. \n",
    "    The stride of the sliding window for each dimension of the input tensor.\n",
    "      padding: A string, either `'VALID'` or `'SAME'`. The padding algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### http://blog.csdn.net/xiaodongxiexie/article/details/74012239\n",
    "    非常好的博客地址，看了之后才算懂了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    产生一个矩阵作为第一次卷积的权重，fliter格式为[filter_height, filter_width, in_channels, out_channels]`，最后32是我们自己设定的数字，\n",
    "    就是产生32个feature去卷积，其中的1是因为我们的数据第三个维度高度为1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 样本的变化\n",
    "     我们一共有N个样本，每个样本是748=28x28x1的数据，分别对应图片数据的长宽高\n",
    "     一般情况下图片都是(RGB)格式，也就是高应该为3。不过mnist数据集的图片只有一个维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#把图片转换成需要的格式[NHWC]，这样x_image[0]就是第一个样本了\n",
    "x_image = tf.reshape(x, [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一次卷积和池化\n",
    "卷积我们使用的padding=SAME,不会改变大小。池化采用[1,2,2,1],也就是长宽方向各缩减一半其中样本数和通道数不变。图片大小变为14x14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二次卷积和池化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为上次输出了32个通道，所以这次的输入通道变成32，输出我们用64个。长宽方向各缩减一半，图片大小变为7x7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu激活，教程里没说激活还需要乘以权重啊"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 池化后样本的形状从[-1,28,28,1]变为[-1,7,7,64]，在把他从4D变成2D,并且第零维度为样本个数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dropout(x, keep_prob, noise_shape=None, seed=None, name=None)\n",
    "    x: A floating point tensor.\n",
    "    keep_prob: A scalar `Tensor` with the same type as x. The probability\n",
    "    that each element is kept.保持原样的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "help(tf.train.AdamOptimizer)\n",
    "    class AdamOptimizer(tensorflow.python.training.optimizer.Optimizer)\n",
    "     |  Optimizer that implements the Adam algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 非常多的变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.92\n",
      "step 100, training accuracy 0.86\n",
      "step 200, training accuracy 0.98\n",
      "step 300, training accuracy 0.9\n",
      "step 400, training accuracy 0.94\n"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  if i%100 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0},session=sess)\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "  sess.run(train_step,feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.9502\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0},session=sess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型试一下，改变np.array的数据类型用astype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float32'), (1, 784))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prex=np.random.rand(784)\n",
    "prex[prex>0.5]=1.0\n",
    "prex[prex<=0.5]=0.0\n",
    "prex=prex.reshape(1,784)\n",
    "prex=prex.astype('float32')\n",
    "prex.dtype,prex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float32'), (50, 784))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].dtype,batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float32'), (1, 784))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prex.dtype,prex.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 怎么两种方法都可以运行了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.64867587e-03,   5.63948648e-04,   1.34338722e-01,\n",
       "          8.11128259e-01,   1.33759268e-05,   5.06391469e-03,\n",
       "          1.65448375e-02,   4.33648791e-04,   2.13822462e-02,\n",
       "          1.88236905e-03]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(y_conv,feed_dict={x:prex,keep_prob:1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=y_conv.eval(feed_dict={x:prex,keep_prob:1.0},session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0.81112826)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.argmax(),result.max()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "预测的到底是几，还需要进一步确认。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "一些权重的变量\n",
    "W                    Variable         <tf.Variable 'Variable:0'<...>4, 10) dtype=float32_ref>\n",
    "W_conv1              Variable         <tf.Variable 'Variable_8:<...>1, 32) dtype=float32_ref>\n",
    "W_conv2              Variable         <tf.Variable 'Variable_10<...>2, 64) dtype=float32_ref>\n",
    "W_fc1                Variable         <tf.Variable 'Variable_12<...> 1024) dtype=float32_ref>\n",
    "W_fc2                Variable         <tf.Variable 'Variable_14<...>4, 10) dtype=float32_ref>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 1, 32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第一层卷积\n",
    "w1=W_conv1.eval(session=sess)\n",
    "w1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 32, 64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第二层卷积\n",
    "w2=W_conv2.eval(session=sess)\n",
    "w2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3136, 1024)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#激活层\n",
    "wf1=W_fc1.eval(session=sess)\n",
    "wf1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 10),)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#全连接\n",
    "wf1=W_fc2.eval(session=sess)\n",
    "wf1.shape,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
