{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numba 入门"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### @jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "@jit\n",
    "def f(x, y):\n",
    "    # A somewhat trivial example\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 50.80 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000000 loops, best of 3: 178 ns per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit f(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 22.49 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000000 loops, best of 3: 94.5 ns per loop\n"
     ]
    }
   ],
   "source": [
    "def f_(x,y):\n",
    "    return x+y\n",
    "%timeit f_(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 限定输入类型和返回类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import  int32\n",
    "\n",
    "@jit(int32(int32, int32))\n",
    "def f(x, y):\n",
    "    # A somewhat trivial example\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(5,2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "@jit \n",
    "def square(x):\n",
    "    return x**2\n",
    "@jit\n",
    "def hypot(x,y):\n",
    "    return math.sqrt(square(x)+square(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 474505.35 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000000 loops, best of 3: 192 ns per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit hypot(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 0 ns, total: 8 µs\n",
      "Wall time: 11.7 µs\n",
      "The slowest run took 18.66 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000000 loops, best of 3: 117 ns per loop\n"
     ]
    }
   ],
   "source": [
    "%time math.sqrt(3**2+4**2)\n",
    "\n",
    "%timeit math.sqrt(3**2+4**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 不使用python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 127526.35 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000000 loops, best of 3: 177 ns per loop\n"
     ]
    }
   ],
   "source": [
    "@jit(nopython=True)\n",
    "def f(x, y):\n",
    "    return x + y\n",
    "%timeit f(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 不使用gil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 133895.18 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000000 loops, best of 3: 249 ns per loop\n"
     ]
    }
   ],
   "source": [
    "@jit(nogil=True)\n",
    "def f(x, y):\n",
    "    return x + y\n",
    "\n",
    "%timeit f(1,2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 177848.04 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000000 loops, best of 3: 178 ns per loop\n"
     ]
    }
   ],
   "source": [
    "@jit(cache=True)\n",
    "def f(x, y):\n",
    "    return x + y\n",
    "%timeit f(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 142086.76 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000000 loops, best of 3: 177 ns per loop\n"
     ]
    }
   ],
   "source": [
    "@jit(nopython=True, parallel=True)\n",
    "def f(x, y):\n",
    "    return x + y\n",
    "%timeit f(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import vectorize,float64,int64,float32\n",
    "\n",
    "@vectorize([int32(int32, int32),\n",
    "            int64(int64, int64),\n",
    "            float32(float32, float32),\n",
    "            float64(float64, float64)])\n",
    "def f(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a=np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 67.22 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000000 loops, best of 3: 397 ns per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit f(a,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 40.30 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000000 loops, best of 3: 365 ns per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit a+a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4],\n",
       "       [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=a.reshape(2,5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 35])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.reduce(a,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  3,  6, 10],\n",
       "       [ 5, 11, 18, 26, 35]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.accumulate(a,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "\n",
    "@cuda.jit\n",
    "def increment_by_one(an_array):\n",
    "    # Thread id in a 1D block\n",
    "    tx = cuda.threadIdx.x\n",
    "    # Block id in a 1D grid\n",
    "    ty = cuda.blockIdx.x\n",
    "    # Block width, i.e. number of threads per block\n",
    "    bw = cuda.blockDim.x\n",
    "    # Compute flattened index inside the array\n",
    "    pos = tx + ty * bw\n",
    "    if pos < an_array.size:  # Check array boundaries\n",
    "        an_array[pos] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 2.59 ms per loop\n"
     ]
    }
   ],
   "source": [
    "an_array=np.arange(1000)\n",
    "%timeit increment_by_one[4,400](an_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 37.63 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000000 loops, best of 3: 1.06 µs per loop\n"
     ]
    }
   ],
   "source": [
    "an_array2=np.arange(1000)\n",
    "%timeit an_array2+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用absolute postion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def increment_by_one(an_array):\n",
    "    pos = cuda.grid(1)\n",
    "    if pos < an_array.size:\n",
    "        an_array[pos] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def increment_a_2D(an_array):\n",
    "    x,y=cuda.grid(2)\n",
    "    if x<an_array.shape[0] and y<an_array.shape[1]:\n",
    "        an_array[x,y]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.67 ms, sys: 2 ms, total: 4.67 ms\n",
      "Wall time: 3.86 ms\n"
     ]
    }
   ],
   "source": [
    "an_array=np.arange(10000).reshape(100,100)\n",
    "\n",
    "threadsperblock = (16, 16)\n",
    "blockspergrid_x = math.ceil(an_array.shape[0] / threadsperblock[0])\n",
    "blockspergrid_y = math.ceil(an_array.shape[1] / threadsperblock[1])\n",
    "blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
    "%time increment_a_2D[blockspergrid, threadsperblock](an_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    1,    2, ...,   97,   98,   99],\n",
       "       [ 100,  101,  102, ...,  197,  198,  199],\n",
       "       [ 200,  201,  202, ...,  297,  298,  299],\n",
       "       ..., \n",
       "       [9700, 9701, 9702, ..., 9797, 9798, 9799],\n",
       "       [9800, 9801, 9802, ..., 9897, 9898, 9899],\n",
       "       [9900, 9901, 9902, ..., 9997, 9998, 9999]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ary=np.arange(1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 复制copy host>device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ary=cuda.to_device(ary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To enqueue the transfer to a stream:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stream = cuda.stream()\n",
    "d_ary = cuda.to_device(ary, stream=stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## copy device>host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hary=d_ary.copy_to_host()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To enqueue the transfer to a stream:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hary=d_ary.copy_to_host(stream=stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with cuda.defer_cleanup():\n",
    "    # all cleanup is deferred in here\n",
    "    #del d_ary\n",
    "    #del increment_by_one \n",
    "    #del increment_a_2D\n",
    "    del stream\n",
    "    # cleanup can occur here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## share memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## writing device funtcions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "@cuda.jit(device=True)\n",
    "def a_f(a,b):\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 20.85 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000000 loops, best of 3: 924 ns per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit f(5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000000 loops, best of 3: 10.6 ns per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit 5+6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## support python features in cuda python "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The following built-in types support are inherited from CPU nopython mode.\n",
    "\n",
    "int\n",
    "float\n",
    "complex\n",
    "bool\n",
    "None\n",
    "tuple"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The following Python constructs are not supported:\n",
    "\n",
    "Exception handling (try .. except, try .. finally)\n",
    "Context management (the with statement)\n",
    "Comprehensions (either list, dict, set or generator comprehensions)\n",
    "Generator (any yield statements)\n",
    "The raise and assert statements are supported. See nopython language support."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The following built-in functions are supported:\n",
    "\n",
    "abs()\n",
    "bool\n",
    "complex\n",
    "enumerate()\n",
    "float\n",
    "int: only the one-argument form\n",
    "len()\n",
    "min(): only the multiple-argument form\n",
    "max(): only the multiple-argument form\n",
    "range: semantics are similar to those of Python 3 even in Python 2: a range object is returned instead of an array of values.\n",
    "round()\n",
    "zip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cmath ,math ,operator ,numpy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Supported numpy features:\n",
    "\n",
    "accessing ndarray attributes .shape, .strides, .ndim, .size, etc..\n",
    "scalar ufuncs that have equivalents in the math module; i.e. np.sin(x[0]), where x is a 1D array.\n",
    "indexing and slicing works.\n",
    "Unsupported numpy features:\n",
    "\n",
    "array creation APIs.\n",
    "array methods.\n",
    "functions that returns a new array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## supported atomic opertions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dir(cuda.atomic)\n",
    "'add',\n",
    " 'compare_and_swap',\n",
    " 'max',\n",
    " 'min'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "@cuda.jit\n",
    "def max_example(result, values):\n",
    "    \"\"\"Find the maximum value in values and store in result[0]\"\"\"\n",
    "    tid = cuda.threadIdx.x\n",
    "    bid = cuda.blockIdx.x\n",
    "    bdim = cuda.blockDim.x\n",
    "    i = (bid * bdim) + tid\n",
    "    cuda.atomic.max(result, 0, values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.9 ms, sys: 2.97 ms, total: 5.87 ms\n",
      "Wall time: 5.4 ms\n",
      "0.999993962091\n"
     ]
    }
   ],
   "source": [
    "arr = np.random.rand(16384)\n",
    "result = np.zeros(1, dtype=np.float64)\n",
    "%time max_example[256,64](result, arr)\n",
    "print(result[0]) # Found using cuda.atomic.max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.26 ms, sys: 0 ns, total: 3.26 ms\n",
      "Wall time: 3.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99999223490376199"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time (max(arr))  # Print max(arr) for comparision (should be equal!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 145 ms, sys: 4.96 ms, total: 150 ms\n",
      "Wall time: 148 ms\n"
     ]
    }
   ],
   "source": [
    "@cuda.jit\n",
    "def max_example_3d(result, values):\n",
    "    \"\"\"\n",
    "    Find the maximum value in values and store in result[0].\n",
    "    Both result and values are 3d arrays.\n",
    "    \"\"\"\n",
    "    i, j, k = cuda.grid(3)\n",
    "    # Atomically store to result[0,1,2] from values[i, j, k]\n",
    "    cuda.atomic.max(result, (0, 1, 2), values[i, j, k])\n",
    "\n",
    "arr = np.random.rand(1000).reshape(10,10,10)\n",
    "result = np.zeros((3, 3, 3), dtype=np.float64)\n",
    "%time max_example_3d[(2, 2, 2), (5, 5, 5)](result, arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 198 µs, sys: 0 ns, total: 198 µs\n",
      "Wall time: 144 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99817789015195324"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time np.max(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random,pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi: 3.14157\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "from numba.cuda.random import create_xoroshiro128p_states, xoroshiro128p_uniform_float32\n",
    "import numpy as np\n",
    "\n",
    "@cuda.jit\n",
    "def compute_pi(rng_states, iterations, out):\n",
    "    \"\"\"Find the maximum value in values and store in result[0]\"\"\"\n",
    "    thread_id = cuda.grid(1)\n",
    "\n",
    "    # Compute pi by drawing random (x, y) points and finding what\n",
    "    # fraction lie inside a unit circle\n",
    "    inside = 0\n",
    "    for i in range(iterations):\n",
    "        x = xoroshiro128p_uniform_float32(rng_states, thread_id)\n",
    "        y = xoroshiro128p_uniform_float32(rng_states, thread_id)\n",
    "        if x**2 + y**2 <= 1.0:\n",
    "            inside += 1\n",
    "\n",
    "    out[thread_id] = 4.0 * inside / iterations\n",
    "\n",
    "threads_per_block = 64*4*4\n",
    "blocks = 24*4*4\n",
    "rng_states = create_xoroshiro128p_states(threads_per_block * blocks, seed=1)\n",
    "out = np.zeros(threads_per_block * blocks, dtype=np.float32)\n",
    "\n",
    "compute_pi[blocks, threads_per_block](rng_states, 10000, out)\n",
    "print('pi:', out.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3733485030324835837, 16058684633881228608)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng_states[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### device seletction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.matrix multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "@cuda.jit\n",
    "def matmul(A, B, C):\n",
    "    \"\"\"Perform square matrix multiplication of C = A * B\n",
    "    something wrong\n",
    "    \"\"\"\n",
    "    \n",
    "    i, j = cuda.grid(2)\n",
    "    if i < C.shape[0] and j < C.shape[1]:\n",
    "        tmp = 0.\n",
    "        for k in range(A.shape[1]):\n",
    "            tmp += A[i, k] * B[k, j]\n",
    "        C[i, j] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 7.76 ms per loop\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 70,  76,  82,  88,  94],\n",
       "       [190, 212, 234, 256, 278],\n",
       "       [310, 348, 386, 424, 462]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "A=np.arange(12).reshape(3,4)\n",
    "B=np.arange(20).reshape(4,5)\n",
    "C=np.arange(15).reshape(3,5)\n",
    "%timeit matmul[(3,5),(1,)](A,B,C)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 59.41 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000000 loops, best of 3: 804 ns per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit np.dot(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import cuda, float32\n",
    "\n",
    "# Controls threads per block and shared memory usage.\n",
    "# The computation will be done on blocks of TPBxTPB elements.\n",
    "TPB = 16\n",
    "\n",
    "@cuda.jit\n",
    "def fast_matmul(A, B, C):\n",
    "    # Define an array in the shared memory\n",
    "    # The size and type of the arrays must be known at compile time\n",
    "    sA = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "    sB = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "\n",
    "    x, y = cuda.grid(2)\n",
    "\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    bpg = cuda.gridDim.x    # blocks per grid\n",
    "\n",
    "    if x >= C.shape[0] and y >= C.shape[1]:\n",
    "        # Quit if (x, y) is outside of valid C boundary\n",
    "        return\n",
    "\n",
    "    # Each thread computes one element in the result matrix.\n",
    "    # The dot product is chunked into dot products of TPB-long vectors.\n",
    "    tmp = 0.\n",
    "    for i in range(bpg):\n",
    "        # Preload data into shared memory\n",
    "        sA[tx, ty] = A[x, ty + i * TPB]\n",
    "        sB[tx, ty] = B[tx + i * TPB, y]\n",
    "\n",
    "        # Wait until all threads finish preloading\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        # Computes partial product on the shared memory\n",
    "        for j in range(TPB):\n",
    "            tmp += sA[tx, j] * sB[j, ty]\n",
    "\n",
    "        # Wait until all threads finish computing\n",
    "        cuda.syncthreads()\n",
    "\n",
    "    C[x, y] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  50,    1,    2,    3,    4],\n",
       "       [-148,    6,    7,    8,    9],\n",
       "       [-177,   11,   12,   13,   14]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=np.arange(12).reshape(3,4)\n",
    "B=np.arange(20).reshape(4,5)\n",
    "C=np.arange(15).reshape(3,5)\n",
    "fast_matmul[3,5](A,B,C)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 µs, sys: 8 µs, total: 31 µs\n",
      "Wall time: 37.7 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 70,  76,  82,  88,  94],\n",
       "       [190, 212, 234, 256, 278],\n",
       "       [310, 348, 386, 424, 462]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time np.dot(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### debuging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "@cuda.reduce\n",
    "def sum_reduce(a, b):\n",
    "    return a + b\n",
    "\n",
    "A = (np.arange(1234, dtype=np.float64)) + 1\n",
    "expect = A.sum()      # numpy sum reduction\n",
    "got = sum_reduce(A)   # cuda sum reduction\n",
    "assert expect == got"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CUDA Ufuncs and Generalized Ufuncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.12998581  10.21331024  10.21221733 ...,  10.16007996  10.34083271\n",
      "  10.63797092]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from numba import vectorize, cuda\n",
    "import numpy as np\n",
    "\n",
    "@vectorize(['float32(float32, float32, float32)',\n",
    "            'float64(float64, float64, float64)'],\n",
    "           target='cuda')\n",
    "def cu_discriminant(a, b, c):\n",
    "    return math.sqrt(b ** 2 - 4 * a * c)\n",
    "\n",
    "N = 10000\n",
    "dtype = np.float32\n",
    "\n",
    "# prepare the input\n",
    "A = np.array(np.random.sample(N), dtype=dtype)\n",
    "B = np.array(np.random.sample(N) + 10, dtype=dtype)\n",
    "C = np.array(np.random.sample(N), dtype=dtype)\n",
    "\n",
    "D = cu_discriminant(A, B, C)\n",
    "\n",
    "print(D)  # print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import vectorize, cuda\n",
    "\n",
    "# define a device function\n",
    "@cuda.jit('float32(float32, float32, float32)', device=True, inline=True)\n",
    "def cu_device_fn(x, y, z):\n",
    "    return x ** y / z\n",
    "\n",
    "# define a ufunc that calls our device function\n",
    "@vectorize(['float32(float32, float32, float32)'], target='cuda')\n",
    "def cu_ufunc(x, y, z):\n",
    "    return cu_device_fn(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 CUDA devices\n",
      "id 0          b'Quadro K620'                              [SUPPORTED]\n",
      "                      compute capability: 5.0\n",
      "                           pci device id: 0\n",
      "                              pci bus id: 129\n",
      "Summary:\n",
      "\t1/1 devices are supported\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.detect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
