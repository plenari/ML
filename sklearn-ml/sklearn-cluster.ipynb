{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster.KMeans?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KMeans\n",
    "cluster.KMeans(n_clusters=8, init='k-means++', n_init=10, max_iter=300, tol=0.0001, precompute_distances='auto', verbose=0, random_state=None, copy_x=True, n_jobs=1, algorithm='auto')\n",
    "\n",
    "基本而言，该算法有三个步骤。第一步选择初始质心，最基本的方法是至从数据集中选择样本  X。初始化后，K-means由两个其他步骤之间的循环组成。第一步将每个样本分配到最近的质心。第二步通过获取分配给每个先前质心的所有样本的平均值来创建新的质心。计算旧质心与新质心之间的差异，并且算法重复这最后两个步骤直到该值小于阈值。换句话说，它重复直到质心不显着移动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster.DBSCAN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBSCAN\n",
    "cluster.DBSCAN(eps=0.5, min_samples=5, metric='euclidean', algorithm='auto', leaf_size=30, p=None, n_jobs=1)\n",
    "\n",
    "该DBSCAN算法将簇视为由低密度区域分隔的高密度区域"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN类的重要参数也分为两类，一类是DBSCAN算法本身的参数，一类是最近邻度量的参数，下面我们对这些参数做一个总结。\n",
    "\n",
    "　　　　1）eps： DBSCAN算法参数，即我们的ϵ-邻域的距离阈值，和样本距离超过ϵ的样本点不在ϵ-邻域内。默认值是0.5.一般需要通过在多组值里面选择一个合适的阈值。eps过大，则更多的点会落在核心对象的ϵ-邻域，此时我们的类别数可能会减少， 本来不应该是一类的样本也会被划为一类。反之则类别数可能会增大，本来是一类的样本却被划分开。\n",
    "\n",
    "　　　　2）min_samples： DBSCAN算法参数，即样本点要成为核心对象所需要的ϵ-邻域的样本数阈值。默认值是5. 一般需要通过在多组值里面选择一个合适的阈值。通常和eps一起调参。在eps一定的情况下，min_samples过大，则核心对象会过少，此时簇内部分本来是一类的样本可能会被标为噪音点，类别数也会变多。反之min_samples过小的话，则会产生大量的核心对象，可能会导致类别数过少。\n",
    "\n",
    "　　　　3）metric：最近邻距离度量参数。可以使用的距离度量较多，一般来说DBSCAN使用默认的欧式距离（即p=2的闵可夫斯基距离）就可以满足我们的需求。可以使用的距离度量参数有：\n",
    "\n",
    "　　　　a) 欧式距离 “euclidean”: ∑i=1n(xi−yi)2−−−−−−−−−−√\n",
    "　　　　b) 曼哈顿距离 “manhattan”： ∑i=1n|xi−yi|\n",
    "　　　　c) 切比雪夫距离“chebyshev”: max|xi−yi|(i=1,2,...n)\n",
    "　　　　d) 闵可夫斯基距离 “minkowski”: ∑i=1n(|xi−yi|)p−−−−−−−−−−−√p p=1为曼哈顿距离， p=2为欧式距离。\n",
    "\n",
    "　　　　e) 带权重闵可夫斯基距离 “wminkowski”: ∑i=1n(w∗|xi−yi|)p−−−−−−−−−−−−−−√p 其中w为特征权重\n",
    "\n",
    "　　　　f) 标准化欧式距离 “seuclidean”: 即对于各特征维度做了归一化以后的欧式距离。此时各样本特征维度的均值为0，方差为1.\n",
    "\n",
    "　　　　g) 马氏距离“mahalanobis”：(x−y)TS−1(x−y)−−−−−−−−−−−−−−−√ 其中，S−1为样本协方差矩阵的逆矩阵。当样本分布独立时， S为单位矩阵，此时马氏距离等同于欧式距离。\n",
    "\n",
    "　　还有一些其他不是实数的距离度量，一般在DBSCAN算法用不上，这里也就不列了。\n",
    "\n",
    "　　　　4）algorithm：最近邻搜索算法参数，算法一共有三种，第一种是蛮力实现，第二种是KD树实现，第三种是球树实现。这三种方法在K近邻法(KNN)原理小结中都有讲述，如果不熟悉可以去复习下。对于这个参数，一共有4种可选输入，‘brute’对应第一种蛮力实现，‘kd_tree’对应第二种KD树实现，‘ball_tree’对应第三种的球树实现， ‘auto’则会在上面三种算法中做权衡，选择一个拟合最好的最优算法。需要注意的是，如果输入样本特征是稀疏的时候，无论我们选择哪种算法，最后scikit-learn都会去用蛮力实现‘brute’。个人的经验，一般情况使用默认的 ‘auto’就够了。 如果数据量很大或者特征也很多，用\"auto\"建树时间可能会很长，效率不高，建议选择KD树实现‘kd_tree’，此时如果发现‘kd_tree’速度比较慢或者已经知道样本分布不是很均匀时，可以尝试用‘ball_tree’。而如果输入样本是稀疏的，无论你选择哪个算法最后实际运行的都是‘brute’。\n",
    "\n",
    "　　　　5）leaf_size：最近邻搜索算法参数，为使用KD树或者球树时， 停止建子树的叶子节点数量的阈值。这个值越小，则生成的KD树或者球树就越大，层数越深，建树时间越长，反之，则生成的KD树或者球树会小，层数较浅，建树时间较短。默认是30. 因为这个值一般只影响算法的运行速度和使用内存大小，因此一般情况下可以不管它。\n",
    "\n",
    "　　　　6） p: 最近邻距离度量参数。只用于闵可夫斯基距离和带权重闵可夫斯基距离中p值的选择，p=1为曼哈顿距离， p=2为欧式距离。如果使用默认的欧式距离不需要管这个参数。\n",
    "\n",
    "　　　　以上就是DBSCAN类的主要参数介绍，其实需要调参的就是两个参数eps和min_samples，这两个值的组合对最终的聚类效果有很大的影响。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cluster.AffinityPropagation\n",
    "cluster.AgglomerativeClustering\n",
    "cluster.Birch\n",
    "cluster.DBSCAN\n",
    "cluster.FeatureAgglomeration\n",
    "cluster.KMeans\n",
    "cluster.MeanShift\n",
    "cluster.MiniBatchKMeans\n",
    "cluster.SpectralBiclustering\n",
    "cluster.SpectralClustering\n",
    "cluster.SpectralCoclustering"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cluster.affinity_propagation\n",
    "cluster.affinity_propagation_\n",
    "cluster.bicluster\n",
    "cluster.birch\n",
    "cluster.dbscan\n",
    "cluster.dbscan_\n",
    "cluster.estimate_bandwidth\n",
    "cluster.get_bin_seeds\n",
    "cluster.hierarchical\n",
    "cluster.k_means\n",
    "cluster.k_means_\n",
    "cluster.linkage_tree\n",
    "cluster.mean_shift\n",
    "cluster.mean_shift_\n",
    "cluster.spectral\n",
    "cluster.spectral_clustering\n",
    "cluster.ward_tree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
